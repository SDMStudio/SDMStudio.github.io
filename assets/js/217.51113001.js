(window.webpackJsonp=window.webpackJsonp||[]).push([[217],{627:function(e,t,i){"use strict";i.r(t);var n=i(34),a=Object(n.a)({},(function(){var e=this.$createElement,t=this._self._c||e;return t("ContentSlotsDistributor",{attrs:{"slot-key":this.$parent.slotKey}},[t("h1",{attrs:{id:"publications"}},[this._v("Publications")]),this._v(" "),t("p",[this._v("The following list of publications is not exhaustive.")]),this._v(" "),t("Publication",{attrs:{title:"Optimally Solving Two-Agent Decentralized POMDPs Under One-Sided Information Sharing",authors:"Y. Xie, J. Dibangoye, O. Buffet",date:"2020",url:"https://proceedings.mlr.press/v119/xie20a.html",abstract:"Optimally solving decentralized partially observable Markov decision processes under either full or no information sharing received significant attention in recent years. However, little is known about how partial information sharing affects existing theory and algorithms. This paper addresses this question for a team of two agents, with one-sided information sharing‚Äî\\ie both agents have imperfect information about the state of the world, but only one has access to what the other sees and does. From the perspective of a central planner, we show that the original problem can be reformulated into an equivalent information-state Markov decision process and solved as such. Besides, we prove that the optimal value function exhibits a specific form of uniform continuity. We also present a heuristic search algorithm utilizing this property and providing the first results for this family of problems. "}}),this._v(" "),t("Publication",{attrs:{title:"On continuous-state MDPs in extensive-form",authors:"J. Arjonilla, D. Albert, J. Dibangoye",date:"Delayed",abstract:"This paper presents a novel‚Äîyet\nmore scalable‚Äîalternative, namely serial central planning for simultaneous decen-\ntralised execution. This methodology pushes the applicability of Bellman‚Äôs principle\nof optimality further and further, raising three new properties. First, it allows a central\nplanner to reason upon sufficient serial statistics instead of prior simultaneous ones.\nNext, it proves that -optimal value functions are piecewise linear and convex in suf-\nficient serial statistics. Finally, it drops the time complexity of the backup operators\nfrom double exponential up to linear."}}),this._v(" "),t("Publication",{attrs:{title:"HSVI pour zs-POSG usant de propri√©t√©s de convexit√©, concavit√©, et Lipschitz-continuit√©.",authors:"A. Delage, O. Buffet and J. S. Dibangoye",date:"2020",url:"https://hal.inria.fr/hal-03080287",abstract:"Many non-trivial sequential decision-making problems are efficiently solved by relying on Bellman's optimality principle, i.e., exploiting the fact that sub-problems are nested recursively within the original problem. Here we show how it can apply to (infinite horizon) 2-player zero-sum partially observable stochastic games (zs-POSGs) by (i) taking a central planner's viewpoint, which can only reason on a sufficient statistic called occupancy state, and (ii) turning such problems into zero-sum occupancy Markov games (zs-OMGs). Then, exploiting the Lipschitz-continuity of the value function in occupancy space, one can derive a version of the HSVI algorithm (Heuristic Search Value Iteration) that provably finds an-Nash equilibrium in finite time."}})],1)}),[],!1,null,null,null);t.default=a.exports}}]);